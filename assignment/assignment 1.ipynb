{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arthor : Wang Chang\n",
    "# zID: z5196324\n",
    "# Finished by 08/03/20\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sad(window1, window2):\n",
    "    return np.sum(np.absolute(window1 - window2))\n",
    "def ssd(window1, window2):\n",
    "    return np.sum(np.power(window1 - window2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roi(img, h_factor, w_factor, window, threshold, step):\n",
    "    height, width = img.shape\n",
    "    h_start = int(h_factor * height)\n",
    "    h_end = h_start + threshold * step + window - 1\n",
    "    w_start = int(w_factor * width)\n",
    "    w_end = w_start + threshold * step + window - 1\n",
    "    \n",
    "    return img[h_start:h_end, w_start:w_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(img):\n",
    "    return cv2.normalize(img, 0, 1, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match(img1, img2, window, step):\n",
    "    height, width = img1.shape\n",
    "    num_window_h = max((height - window) / step,0) + 1\n",
    "    num_window_w = max((width - window) / step,0) + 1\n",
    "    \n",
    "    #init\n",
    "    img1_h_best, img1_w_best, img2_h_best, img2_w_best = 0, 0, 0, 0\n",
    "    window1 = img1[0:window, 0:window]\n",
    "    window2 = img2[0:window, 0:window]\n",
    "    best_match = ssd(window1, window2)\n",
    "    for  img1_h in range(0, height - window + 1, step):\n",
    "        for img1_w in range(0, width - window + 1, step):\n",
    "            window1 = img1[img1_h:(img1_h + window), img1_w:(img1_w + window)]\n",
    "            for  img2_h in range(0, height - window + 1, step):\n",
    "                for img2_w in range(0, width - window + 1, step):\n",
    "                    window2 = img2[img2_h:(img2_h + window), img2_w:(img2_w + window)]\n",
    "                    curr_match = ssd(window1, window2)\n",
    "                    if curr_match < best_match:\n",
    "                        best_match = curr_match\n",
    "                        img1_h_best, img1_w_best = img1_h, img1_w\n",
    "                        img2_h_best, img2_w_best = img2_h, img2_w\n",
    "                        \n",
    "    return img1_h_best, img1_w_best, img2_h_best, img2_w_best, best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1(img_name, h_factor, w_factor, window, threshold, step):\n",
    "    start_time = time.clock()\n",
    "    img = cv2.imread(img_name)\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    #split image\n",
    "    sub_height = int(height/3)\n",
    "    blue = img[0:sub_height, :, 0]\n",
    "    green = img[sub_height:sub_height * 2, :, 1]\n",
    "    red = img[sub_height * 2:sub_height * 3, :, 2]\n",
    "    \n",
    "    #scale the parameters\n",
    "    scale_factor = max(int(min(sub_height / 350, width / 400)), 1)\n",
    "    window = window * scale_factor\n",
    "    step = step * scale_factor\n",
    "    \n",
    "    #get roi\n",
    "    blue_roi = get_roi(blue, h_factor, w_factor, window, threshold, step)\n",
    "    green_roi = get_roi(green, h_factor, w_factor, window, threshold, step)\n",
    "    red_roi = get_roi(red, h_factor, w_factor, window, threshold, step)\n",
    "    \n",
    "    #normalization, to avoid image too bright or dark, and the strange parameters\n",
    "    normalized_blue = normalization(blue_roi)\n",
    "    normalized_green = normalization(green_roi)\n",
    "    normalized_red = normalization(red_roi)\n",
    "    \n",
    "    #get best match of green based on blue\n",
    "    rows, cols = blue.shape\n",
    "    b_h, b_w, g_h, g_w, best_match = get_best_match(normalized_blue, normalized_green, window, step)\n",
    "    #print('match blue and green :', str([b_h, b_w, g_h, g_w]))\n",
    "    changed_green = cv2.warpAffine(green, np.float32([[1,0,b_w - g_w], [0,1,b_h - g_h]]), (cols, rows))\n",
    "    \n",
    "    #get best match of red based on blue\n",
    "    b_h, b_w, r_h, r_w, best_match = get_best_match(normalized_blue, normalized_red, window, step)\n",
    "    #print('match blue and red :', str([b_h, b_w, r_h, r_w]))\n",
    "    changed_red = cv2.warpAffine(red, np.float32([[1,0,b_w - r_w], [0,1,b_h - r_h]]), (cols, rows))\n",
    "    \n",
    "    #merge img\n",
    "    merged_img = cv2.merge([blue, changed_green, changed_red])\n",
    "    end_time = time.clock()\n",
    "    print('running time : ' + str(end_time - start_time))\n",
    "    return merged_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running time : 1.8292500427654153\n",
      "running time : 2.3302335485497094\n",
      "running time : 3.941033899838459\n",
      "running time : 0.7934321803724718\n",
      "running time : 0.732691463628063\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_img1 = task1('s1.jpg', 0.60, 0.40, 40, 11, 1)\n",
    "merged_img2 = task1('s2.jpg', 0.50, 0.50, 40, 12, 1)\n",
    "merged_img3 = task1('s3.jpg', 0.50, 0.75, 30, 15, 1)\n",
    "merged_img4 = task1('s4.jpg', 0.50, 0.50, 30, 10, 1)\n",
    "merged_img5 = task1('s5.jpg', 0.50, 0.50, 30, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task1-img1.jpg', merged_img1)\n",
    "cv2.imwrite('task1-img2.jpg', merged_img2)\n",
    "cv2.imwrite('task1-img3.jpg', merged_img3)\n",
    "cv2.imwrite('task1-img4.jpg', merged_img4)\n",
    "cv2.imwrite('task1-img5.jpg', merged_img5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_match_2(img1, img2, h_new1, w_new1, h_new2, w_new2, window, step):\n",
    "    #scale the parameters\n",
    "    height, width = img1.shape\n",
    "    scale_factor = max(int(min(height / 350, width / 400)), 1)\n",
    "    window = window * scale_factor\n",
    "    step= step * scale_factor\n",
    "    #init the result\n",
    "    window1 = img1[h_new1 : h_new1 + window, w_new1 : w_new1 + window]\n",
    "    window2 = img2[h_new2 : h_new2 + window, w_new2 : w_new2 + window]\n",
    "    img1_h_best, img1_w_best, img2_h_best, img2_w_best = h_new1, w_new1, h_new2, w_new2\n",
    "    best_match = ssd(window1, window2)\n",
    "    #general other candidates, the 8 unit around\n",
    "    candidates = [[h_new1 - step, w_new1 - step, h_new2 - step, w_new2 - step], \\\n",
    "                  [h_new1 - step, w_new1 + step, h_new2 - step, w_new2 + step], \\\n",
    "                  [h_new1 - step, w_new1, h_new2 - step, w_new2 - step], \\\n",
    "                  [h_new1, w_new1 - step, h_new2, w_new2 - step], \\\n",
    "                  [h_new1, w_new1 + step, h_new2, w_new2 + step],\\\n",
    "                  [h_new1 + step, w_new1 - step, h_new2 + step, w_new2 - step], \\\n",
    "                  [h_new1 + step, w_new1 + step, h_new2 + step, w_new2 + step], \\\n",
    "                  [h_new1 + step, w_new1, h_new2 + step, w_new2]]\n",
    "    #finding best match\n",
    "    for i in candidates[:]:\n",
    "        h_candidate1, w_candidate1, h_candidate2, w_candidate2 = i\n",
    "        if h_candidate1 < 0 or h_candidate1 + window >= height or h_candidate2 < 0 or h_candidate2 + window >= height or w_candidate1 < 0 or w_candidate1 + window >= width or w_candidate2 < 0 or w_candidate2 + window >= width:\n",
    "            continue\n",
    "        window1 = img1[h_candidate1:h_candidate1 + window, w_candidate1:w_candidate1 + window]\n",
    "        window2 = img2[h_candidate2:h_candidate2 + window, w_candidate2:w_candidate2 + window]\n",
    "        curr_match = ssd(window1, window2)\n",
    "        if curr_match < best_match:\n",
    "            best_match = curr_match\n",
    "            img1_h_best, img1_w_best, img2_h_best, img2_w_best = h_candidate1, w_candidate1, h_candidate2, w_candidate2\n",
    "    return img1_h_best, img1_w_best, img2_h_best, img2_w_best, best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid(img1, img2, sharpen_factor, h_factor, w_factor, window, threshold, step):\n",
    "    img1_down1 = cv2.pyrDown(img1)\n",
    "    img2_down1 = cv2.pyrDown(img2)\n",
    "    \n",
    "    img1_down2 = cv2.pyrDown(img1_down1)\n",
    "    img2_down2 = cv2.pyrDown(img2_down1)\n",
    "    \n",
    "    # get roi\n",
    "    img1_down2_roi = get_roi(img1_down2, h_factor, w_factor, window, threshold, step)\n",
    "    img2_down2_roi = get_roi(img2_down2, h_factor, w_factor, window, threshold, step)\n",
    "    \n",
    "    # get best match\n",
    "    h1,w1,h2,w2,best_match = get_best_match(img1_down2_roi, img2_down2_roi, window, step)\n",
    "    h1,w1,h2,w2,best_match = get_best_match_2(img1_down1, img2_down1, h1*2, w1*2, h2*2, w2*2, window, step)\n",
    "    h1,w1,h2,w2,best_match = get_best_match_2(img1, img2, h1*2, w1*2, h2*2, w2*2, window, step)\n",
    "    \n",
    "    return h1, w1, h2, w2, best_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2(img_name, sharpen_factor, h_factor, w_factor, window, threshold, step):\n",
    "    start_time = time.clock()\n",
    "    img = cv2.imread(img_name)\n",
    "    \n",
    "    # split the img\n",
    "    sub_height = int(img.shape[0] / 3)\n",
    "    blue = img[0:sub_height,:,0]\n",
    "    green = img[sub_height:sub_height*2,:,1]\n",
    "    red = img[sub_height*2:sub_height*3,:,2]\n",
    "    \n",
    "    # normalization\n",
    "    normalized_blue = normalization(blue)\n",
    "    normalized_green = normalization(green)\n",
    "    normalized_red = normalization(red)\n",
    "    \n",
    "    #get best match of green based on blue\n",
    "    rows, cols = blue.shape\n",
    "    b_h, b_w, g_h, g_w, best_match = pyramid(normalized_blue, normalized_green, sharpen_factor, h_factor, w_factor, window, threshold, step)\n",
    "    #print('match blue and green :', str([b_h, b_w, g_h, g_w]))\n",
    "    changed_green = cv2.warpAffine(green, np.float32([[1,0,b_w - g_w], [0,1,b_h - g_h]]), (cols, rows))\n",
    "    \n",
    "    #get best match of red based on blue\n",
    "    b_h, b_w, r_h, r_w, best_match = pyramid(normalized_blue, normalized_red, sharpen_factor, h_factor, w_factor, window, threshold, step)\n",
    "    #print('match blue and red :', str([b_h, b_w, r_h, r_w]))\n",
    "    changed_red = cv2.warpAffine(red, np.float32([[1,0,b_w - r_w], [0,1,b_h - r_h]]), (cols, rows))\n",
    "    \n",
    "    merged_img = cv2.merge([blue, changed_green, changed_red])\n",
    "    end_time = time.clock()\n",
    "    print('overall time : ' + str(end_time - start_time))\n",
    "    return merged_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time : 0.016256783701024347\n",
      "overall time : 0.016067154146309548\n",
      "overall time : 0.016944585898434283\n",
      "overall time : 0.013579846486974745\n",
      "overall time : 0.014733031216580983\n"
     ]
    }
   ],
   "source": [
    "merged_img11 = task2('s1.jpg', 20, 0.8, 0, 50, 15, 1)\n",
    "merged_img22 = task2('s2.jpg', 20, 0.8, 0, 30, 15, 1)\n",
    "merged_img33 = task2('s3.jpg', 20, 0.8, 0, 20, 15, 1)\n",
    "merged_img44 = task2('s4.jpg', 20, 0.8, 0, 40, 10, 1)\n",
    "merged_img55 = task2('s5.jpg', 20, 0.8, 0.5, 50, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task2-img1.jpg', merged_img11)\n",
    "cv2.imwrite('task2-img2.jpg', merged_img22)\n",
    "cv2.imwrite('task2-img3.jpg', merged_img33)\n",
    "cv2.imwrite('task2-img4.jpg', merged_img44)\n",
    "cv2.imwrite('task2-img5.jpg', merged_img55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time : 8.569026145569918\n"
     ]
    }
   ],
   "source": [
    "merged_img111 = task2('00549u.jpg', 20, 0.8, 0, 50, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task2-high-pixel 1.jpg', merged_img111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time : 7.795815191776718\n"
     ]
    }
   ],
   "source": [
    "merged_img222 = task2('00911u.jpg', 20, 0.8, 0, 50, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task2-high-pixel 2.jpg', merged_img222)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(img, lines, int_upper, int_lower, int_left, int_right):\n",
    "    height, width = img.shape[:2]\n",
    "    left_vertical, right_vertical, upper_horizontal, lower_horizontal = 0, width - 1, 0,height - 1\n",
    "    for rho, theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = int(a * rho)\n",
    "        y0 = int(b * rho)\n",
    "        if a > b:\n",
    "            if x0 < width / 2:\n",
    "                left_vertical = max(x0, left_vertical)\n",
    "            else:\n",
    "                right_vertical = min(x0, right_vertical)\n",
    "        else:\n",
    "            if y0 < width / 2:\n",
    "                upper_horizontal = max(y0, upper_horizontal)\n",
    "            else:\n",
    "                lower_horizontal = min(y0, lower_horizontal)\n",
    "    return img[(upper_horizontal + int_upper):(lower_horizontal - int_lower), (left_vertical + int_left):(right_vertical - int_right)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the border\n",
    "def remove_border(img, kernel_size = 5, canny_min = 50, canny_max = 150, int_upper = 10, int_lower = 20, int_left = 15, int_right = 15):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)\n",
    "    edged_img = cv2.Canny(gray, canny_min, canny_max)\n",
    "    lines = cv2.HoughLines(edged_img, 1, np.pi/180, 200)\n",
    "    cut_img = cut(img, lines, int_upper, int_lower, int_left, int_right)\n",
    "    return cut_img\n",
    "    \n",
    "cut_img = remove_border(merged_img1, kernel_size = 5, canny_min = 50, canny_max = 150, int_upper = 10, int_lower = 20, int_left = 15, int_right = 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task3-cut-1.jpg', cut_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(img, factor):\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_enhanced = ImageEnhance.Contrast(img_pil).enhance(factor)\n",
    "    img_cv = np.array(img_enhanced, dtype = np.uint8)\n",
    "    return img_cv\n",
    "contrast_img = contrast(cut_img, 1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task3-contrast.jpg', contrast_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness(img, factor):\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_enhanced = ImageEnhance.Brightness(img_pil).enhance(factor)\n",
    "    img_cv = np.array(img_enhanced, dtype = np.uint8)\n",
    "    return img_cv\n",
    "brightness_img = contrast(contrast_img, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task3-brightness.jpg', brightness_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness(img, factor):\n",
    "    img_pil = Image.fromarray(img)\n",
    "    img_enhanced = ImageEnhance.Sharpness(img_pil).enhance(factor)\n",
    "    img_cv = np.array(img_enhanced, dtype = np.uint8)\n",
    "    return img_cv\n",
    "sharpness_img = contrast(brightness_img, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('task3-sharpness.jpg', sharpness_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
